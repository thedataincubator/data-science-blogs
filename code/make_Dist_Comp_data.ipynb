{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ranking Distributed Computing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib2\n",
    "import dill\n",
    "import time\n",
    "import json\n",
    "from datetime import date, timedelta\n",
    "from bs4 import BeautifulSoup\n",
    "import unicodedata\n",
    "import csv\n",
    "import sys\n",
    "sys.path.append('../code')\n",
    "sys.path.append('../data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create list of packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 https://www.digitalocean.com/community/tutorials/hadoop-storm-samza-spark-and-flink-big-data-frameworks-compared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pkgs1 = ['apache hadoop', 'apache storm', 'apache samza','apache spark', 'apache flink']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 https://github.com/onurakpolat/awesome-bigdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r2 = requests.get('https://github.com/onurakpolat/awesome-bigdata')\n",
    "soup2 = BeautifulSoup(r2.text, 'lxml')\n",
    "pkgs2 = []\n",
    "for ana in soup2.findAll('a', attrs={'span class': None}):\n",
    "    if ana.parent.name == 'li':       \n",
    "        pkgs2.append(str(ana.text).lower())\n",
    "pkgs2 = pkgs2[55:110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ibm streams', 'apache hadoop', 'tigon', 'pachyderm', 'addthis hydra', 'amplab simr', 'apache apex', 'apache beam', 'apache crunch', 'apache datafu', 'apache flink', 'apache gearpump', 'apache gora', 'apache hama', 'apache mapreduce', 'apache pig', 'apache reef', 'apache s4', 'apache spark', 'apache spark streaming', 'apache storm', 'apache samza', 'apache tez', 'apache twill', 'cascalog', 'cheetah', 'concurrent cascading', 'damballa parkour', 'datasalt pangool', 'datatorrent stram', 'facebook corona', 'facebook peregrine', 'facebook scuba', 'google dataflow', 'google mapreduce', 'google millwheel', 'ibm streams', 'jaql', 'kite', 'metamarkets druid', 'netflix pigpen', 'nokia disco', 'onyx', 'pinterest pinlater', 'pydoop', 'rackerlabs blueflood', 'skale', 'stratosphere', 'streamdrill', 'streamsx.topology', 'tuktu', 'twitter heron', 'twitter scalding', 'twitter summingbird', 'twitter tsar']\n"
     ]
    }
   ],
   "source": [
    "print pkgs2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 http://bigdata.andreamostosi.name/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r3 = requests.get('http://bigdata.andreamostosi.name/')\n",
    "soup3 = BeautifulSoup(r3.text, 'lxml')\n",
    "pkgs3 = []\n",
    "for ana in soup3.findAll('td'):\n",
    "    if '\\n' not in ana.text:\n",
    "        pkgs3.append(unicodedata.normalize('NFKD', ana.text).encode('ascii','ignore').lower())\n",
    "pkgs3 = pkgs3[:101]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apache hadoop', 'addthis hydra', 'akela', 'amazon lambda', 'amazon spice', 'ampcrowd', 'amplab g-ola', 'amplab simr', 'apache crunch', 'apache datafu', 'apache flink', 'apache gora', 'apache hama', 'apache ignite', 'apache mapreduce', 'apache pig', 'apache s4', 'apache spark', 'apache spark streaming', 'apache storm', 'apache tez', 'apache twill', 'arvados', 'blaze', 'cascalog', 'cheetah', 'concurrent cascading', 'damballa parkour', 'datasalt pangool', 'datatorrent stram', 'distributedr', 'drools', 'ebay oink', 'esper', 'facebook corona', 'facebook peregrine', 'facebook scuba', 'gearpump', 'geotrellis', 'getstream stream framework', 'gis tools for hadoop', 'google dataflow', 'google flumejava', 'google mapreduce', 'google millwheel', 'graphlab dato', 'hazelcast', 'hparser', 'ibm streams', 'jaql', 'kite', 'kryo', 'linkedin cubert', 'lipstick', 'metamarkers druid', 'microsoft azure stream analytics', 'microsoft orleans', 'microsoft project orleans', 'microsoft trill', 'netflix aegisthus', 'netflix lipstick', 'netflix mantis', 'netflix pigpen', 'netflix staash', 'netflix surus', 'netflix zeno', 'nextflow', 'nokia disco', 'oryx', 'pachyderm', 'parsely streamparse', 'pigpen', 'pinterest pinlater', 'pubnub', 'pydoop', 'scaleout hserver', 'seqpig', 'sigmoidanalytics spork', 'snap', 'spark-dataflow', 'spatialhadoop', 'spring for apache hadoop', 'sqlstream blaze', 'stratio crossdata', 'stratio decision', 'stratio streaming', 'stratosphere', 'streamdrill', 'succinct spark', 'sumo logic', 'teradata querygrid', 'tibco activespaces', 'tigon', 'torch', 'trident', 'twitter crane', 'twitter gizzard', 'twitter heron', 'twitter scalding', 'twitter summingbird', 'twitter tsar']\n"
     ]
    }
   ],
   "source": [
    "print pkgs3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combine lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pkgs = list(set(pkgs1 + pkgs2 + pkgs3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pkgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apache storm', 'stratio crossdata', 'kite', 'twitter gizzard', 'apache reef', 'pachyderm', 'nextflow', 'cascalog', 'parsely streamparse', 'datasalt pangool', 'succinct spark', 'blaze', 'netflix staash', 'skale', 'metamarkets druid', 'distributedr', 'twitter tsar', 'sigmoidanalytics spork', 'amplab simr', 'stratio streaming', 'apache gora', 'ebay oink', 'rackerlabs blueflood', 'torch', 'pinterest pinlater', 'google mapreduce', 'apache twill', 'google dataflow', 'apache mapreduce', 'stratio decision', 'lipstick', 'hazelcast', 'datatorrent stram', 'apache hadoop', 'spatialhadoop', 'gis tools for hadoop', 'twitter crane', 'drools', 'gearpump', 'kryo', 'apache ignite', 'sqlstream blaze', 'ampcrowd', 'arvados', 'pigpen', 'netflix aegisthus', 'apache apex', 'netflix mantis', 'google flumejava', 'google millwheel', 'apache pig', 'metamarkers druid', 'twitter scalding', 'apache beam', 'twitter heron', 'netflix zeno', 'microsoft trill', 'tibco activespaces', 'pubnub', 'twitter summingbird', 'microsoft project orleans', 'apache samza', 'amazon lambda', 'seqpig', 'oryx', 'amplab g-ola', 'netflix lipstick', 'ibm streams', 'apache spark streaming', 'teradata querygrid', 'onyx', 'apache spark', 'snap', 'sumo logic', 'nokia disco', 'netflix surus', 'apache s4', 'netflix pigpen', 'stratosphere', 'spring for apache hadoop', 'facebook scuba', 'streamsx.topology', 'apache flink', 'apache gearpump', 'tuktu', 'geotrellis', 'hparser', 'linkedin cubert', 'amazon spice', 'spark-dataflow', 'apache datafu', 'damballa parkour', 'microsoft azure stream analytics', 'esper', 'scaleout hserver', 'akela', 'getstream stream framework', 'cheetah', 'facebook corona', 'addthis hydra', 'trident', 'graphlab dato', 'facebook peregrine', 'concurrent cascading', 'pydoop', 'jaql', 'apache tez', 'apache hama', 'streamdrill', 'microsoft orleans', 'apache crunch', 'tigon']\n"
     ]
    }
   ],
   "source": [
    "print pkgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#packages without github repos or mirrors are excluded\n",
    "excluded_pkgs = ['amazon lambda', 'amazon spice', 'amplab g-ola', 'amplab simr', 'apache crunch', 'cheetah', 'datatorrent stram',\n",
    "                'esper', 'facebook corona', 'facebook peregrine', 'facebook scuba', 'google dataflow', 'google flumejava', 'google mapreduce', \n",
    "              'google millwheel', 'graphlab dato','ibm streams','jaql', 'metamarkers druid','microsoft azure stream analytics', \n",
    "             'microsoft orleans', 'microsoft project orleans', 'microsoft trill','netflix mantis','pinterest pinlater', 'pubnub',\n",
    "                  'stratosphere', 'sqlstream blaze', 'sumo logic', 'teradata querygrid', 'tibco activespaces', 'torch', 'lipstick',\n",
    "                 'trident', 'twitter crane', 'twitter tsar']\n",
    "\n",
    "for package in excluded_pkgs:\n",
    "    pkgs.remove(package) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pkgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apache storm', 'stratio crossdata', 'kite', 'twitter gizzard', 'apache reef', 'pachyderm', 'nextflow', 'cascalog', 'parsely streamparse', 'datasalt pangool', 'succinct spark', 'blaze', 'netflix staash', 'skale', 'metamarkets druid', 'distributedr', 'sigmoidanalytics spork', 'stratio streaming', 'apache gora', 'ebay oink', 'rackerlabs blueflood', 'apache twill', 'apache mapreduce', 'stratio decision', 'hazelcast', 'apache hadoop', 'spatialhadoop', 'gis tools for hadoop', 'drools', 'gearpump', 'kryo', 'apache ignite', 'ampcrowd', 'arvados', 'pigpen', 'netflix aegisthus', 'apache apex', 'apache pig', 'twitter scalding', 'apache beam', 'twitter heron', 'netflix zeno', 'twitter summingbird', 'apache samza', 'seqpig', 'oryx', 'netflix lipstick', 'apache spark streaming', 'onyx', 'apache spark', 'snap', 'nokia disco', 'netflix surus', 'apache s4', 'netflix pigpen', 'spring for apache hadoop', 'streamsx.topology', 'apache flink', 'apache gearpump', 'tuktu', 'geotrellis', 'hparser', 'linkedin cubert', 'spark-dataflow', 'apache datafu', 'damballa parkour', 'scaleout hserver', 'akela', 'getstream stream framework', 'addthis hydra', 'concurrent cascading', 'pydoop', 'apache tez', 'apache hama', 'streamdrill', 'tigon']\n"
     ]
    }
   ],
   "source": [
    "print pkgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## github stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"../code/secrets/github-token.nogit\", \"rb\") as f:\n",
    "    token = f.read()\n",
    "\n",
    "headers = {'Authorization': 'token %s' % token}\n",
    "\n",
    "def get_data_from_search(query):\n",
    "    \"\"\"Use github search to return stars, forks for top query result\"\"\"\n",
    "    r = requests.get('https://api.github.com/search/repositories?q='+\\\n",
    "                             query, \n",
    "                     headers=headers)\n",
    "    r.raise_for_status()\n",
    "    try:\n",
    "        res = r.json()['items'][0]\n",
    "        return {'package': query, 'full_name': res['full_name'],\n",
    "                'stars': res['stargazers_count'], 'forks': res['forks_count']}\n",
    "    except:\n",
    "        return {'package': query, 'full_name': 'NA',\n",
    "                'stars': 0, 'forks': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "# use generator to avoid repeat API calls; API limit with token: 30 api calls/min\n",
    "github_data = []\n",
    "for ii in range(int(len(pkgs)/20)):\n",
    "    start = ii*20\n",
    "    end = (ii+1)*20\n",
    "    data = [res for res in (get_data_from_search(query) for query in pkgs[start:end]) if res is not None]\n",
    "    github_data.extend(data)\n",
    "    time.sleep(61) \n",
    "data = [res for res in (get_data_from_search(query) for query in pkgs[end:]) if res is not None]\n",
    "github_data.extend(data)\n",
    "print \"DONE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "github = pd.DataFrame(github_data)[['package', 'full_name', 'forks', 'stars']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## github search doesn't always return the correct repo. function to replace repos and stats\n",
    "def replace_repo_stats(package, repo_address):\n",
    "    r = requests.get('https://api.github.com/repos/'+repo_address, headers=headers)\n",
    "    res = r.json()\n",
    "    github.loc[github['package'] == package, 'full_name'] = repo_address\n",
    "    github.loc[github['package'] == package, 'forks'] = res['forks_count']\n",
    "    github.loc[github['package'] == package, 'stars'] = res['stargazers_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "good_repos = [('addthis hydra','addthis/hydra'),\n",
    "              ('stratio crossdata','Stratio/crossdata'),\n",
    "              ('twitter gizzard','twitter-archive/gizzard'),\n",
    "              ('concurrent cascading', 'cwensel/cascading'), \n",
    "              ('datasalt pangool', 'datasalt/pangool'),\n",
    "              ('netflix staash','Netflix/staash'),\n",
    "              ('metamarkets druid','druid-io/druid'),\n",
    "              ('sigmoidanalytics spork', 'sigmoidanalytics/spork'),\n",
    "              ('ebay oink', 'eBay/oink'),\n",
    "              ('rackerlabs blueflood', 'rackerlabs/blueflood'),\n",
    "              ('apache mapreduce','apache/hadoop-mapreduce'),\n",
    "              ('stratio decision', 'Stratio/Decision'),\n",
    "              ('netflix aegisthus', 'Netflix/aegisthus'),\n",
    "              ('twitter scalding', 'twitter/scalding'),\n",
    "              ('twitter summingbird','twitter/summingbird'),\n",
    "              ('netflix lipstick', 'Netflix/Lipstick'),\n",
    "              ('nokia disco', 'discoproject/disco'),\n",
    "              ('netflix surus', 'Netflix/Surus'),\n",
    "              ('netflix pigpen', 'Netflix/PigPen'),\n",
    "              ('linkedin cubert', 'linkedin/Cubert'),\n",
    "              ('damballa parkour', 'damballa/parkour'),\n",
    "              ('getstream stream framework', 'tschellenbach/Stream-Framework')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for (package, r_address) in good_repos:\n",
    "    replace_repo_stats(package, r_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "github.to_csv(\"../data/DC_results_github.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>package</th>\n",
       "      <th>full_name</th>\n",
       "      <th>forks</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>apache spark</td>\n",
       "      <td>apache/spark</td>\n",
       "      <td>13341</td>\n",
       "      <td>14241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>apache hadoop</td>\n",
       "      <td>apache/hadoop</td>\n",
       "      <td>3452</td>\n",
       "      <td>3712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apache storm</td>\n",
       "      <td>apache/storm</td>\n",
       "      <td>3295</td>\n",
       "      <td>4471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>apache flink</td>\n",
       "      <td>apache/flink</td>\n",
       "      <td>1851</td>\n",
       "      <td>2686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>metamarkets druid</td>\n",
       "      <td>druid-io/druid</td>\n",
       "      <td>1311</td>\n",
       "      <td>5401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>drools</td>\n",
       "      <td>kiegroup/drools</td>\n",
       "      <td>1179</td>\n",
       "      <td>1071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>hazelcast</td>\n",
       "      <td>hazelcast/hazelcast</td>\n",
       "      <td>917</td>\n",
       "      <td>2210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>apache beam</td>\n",
       "      <td>apache/beam</td>\n",
       "      <td>800</td>\n",
       "      <td>1372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>apache ignite</td>\n",
       "      <td>apache/ignite</td>\n",
       "      <td>678</td>\n",
       "      <td>1165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>twitter scalding</td>\n",
       "      <td>twitter/scalding</td>\n",
       "      <td>637</td>\n",
       "      <td>2868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>twitter heron</td>\n",
       "      <td>twitter/heron</td>\n",
       "      <td>518</td>\n",
       "      <td>2886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>kryo</td>\n",
       "      <td>EsotericSoftware/kryo</td>\n",
       "      <td>503</td>\n",
       "      <td>2838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>apache pig</td>\n",
       "      <td>apache/pig</td>\n",
       "      <td>411</td>\n",
       "      <td>503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>getstream stream framework</td>\n",
       "      <td>tschellenbach/Stream-Framework</td>\n",
       "      <td>388</td>\n",
       "      <td>3137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>snap</td>\n",
       "      <td>snap-stanford/snap</td>\n",
       "      <td>348</td>\n",
       "      <td>685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>oryx</td>\n",
       "      <td>OryxProject/oryx</td>\n",
       "      <td>312</td>\n",
       "      <td>1224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>spring for apache hadoop</td>\n",
       "      <td>spring-projects/spring-hadoop</td>\n",
       "      <td>308</td>\n",
       "      <td>489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>blaze</td>\n",
       "      <td>blaze/blaze</td>\n",
       "      <td>289</td>\n",
       "      <td>2109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>nokia disco</td>\n",
       "      <td>discoproject/disco</td>\n",
       "      <td>248</td>\n",
       "      <td>1471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>twitter summingbird</td>\n",
       "      <td>twitter/summingbird</td>\n",
       "      <td>247</td>\n",
       "      <td>1883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>concurrent cascading</td>\n",
       "      <td>cwensel/cascading</td>\n",
       "      <td>223</td>\n",
       "      <td>297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>twitter gizzard</td>\n",
       "      <td>twitter-archive/gizzard</td>\n",
       "      <td>209</td>\n",
       "      <td>2143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pachyderm</td>\n",
       "      <td>pachyderm/pachyderm</td>\n",
       "      <td>207</td>\n",
       "      <td>2143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kite</td>\n",
       "      <td>kite-sdk/kite</td>\n",
       "      <td>203</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>geotrellis</td>\n",
       "      <td>locationtech/geotrellis</td>\n",
       "      <td>192</td>\n",
       "      <td>606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cascalog</td>\n",
       "      <td>nathanmarz/cascalog</td>\n",
       "      <td>179</td>\n",
       "      <td>1306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>gis tools for hadoop</td>\n",
       "      <td>Esri/gis-tools-for-hadoop</td>\n",
       "      <td>169</td>\n",
       "      <td>311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>apache spark streaming</td>\n",
       "      <td>yahoo/streaming-benchmarks</td>\n",
       "      <td>161</td>\n",
       "      <td>294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>apache samza</td>\n",
       "      <td>apache/samza</td>\n",
       "      <td>160</td>\n",
       "      <td>352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>apache apex</td>\n",
       "      <td>apache/apex-core</td>\n",
       "      <td>158</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>apache gora</td>\n",
       "      <td>apache/gora</td>\n",
       "      <td>66</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>linkedin cubert</td>\n",
       "      <td>linkedin/Cubert</td>\n",
       "      <td>60</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>spark-dataflow</td>\n",
       "      <td>jhlch/spark-dataflow</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>netflix pigpen</td>\n",
       "      <td>Netflix/PigPen</td>\n",
       "      <td>57</td>\n",
       "      <td>469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>distributedr</td>\n",
       "      <td>vertica/DistributedR</td>\n",
       "      <td>57</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>pigpen</td>\n",
       "      <td>Netflix/PigPen</td>\n",
       "      <td>57</td>\n",
       "      <td>469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>netflix zeno</td>\n",
       "      <td>Netflix/zeno</td>\n",
       "      <td>55</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>apache mapreduce</td>\n",
       "      <td>apache/hadoop-mapreduce</td>\n",
       "      <td>54</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>arvados</td>\n",
       "      <td>curoverse/arvados</td>\n",
       "      <td>47</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>pydoop</td>\n",
       "      <td>crs4/pydoop</td>\n",
       "      <td>46</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>succinct spark</td>\n",
       "      <td>amplab/succinct</td>\n",
       "      <td>43</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>stratio crossdata</td>\n",
       "      <td>Stratio/crossdata</td>\n",
       "      <td>40</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>streamsx.topology</td>\n",
       "      <td>IBMStreams/streamsx.topology</td>\n",
       "      <td>36</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>netflix staash</td>\n",
       "      <td>Netflix/staash</td>\n",
       "      <td>36</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>tigon</td>\n",
       "      <td>caskdata/tigon</td>\n",
       "      <td>35</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>akela</td>\n",
       "      <td>mozilla-metrics/akela</td>\n",
       "      <td>29</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>apache twill</td>\n",
       "      <td>apache/twill</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>sigmoidanalytics spork</td>\n",
       "      <td>sigmoidanalytics/spork</td>\n",
       "      <td>26</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>skale</td>\n",
       "      <td>skale-me/skale-engine</td>\n",
       "      <td>23</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>damballa parkour</td>\n",
       "      <td>damballa/parkour</td>\n",
       "      <td>19</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>apache s4</td>\n",
       "      <td>apache/incubator-s4</td>\n",
       "      <td>17</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>tuktu</td>\n",
       "      <td>UnderstandLingBV/Tuktu</td>\n",
       "      <td>15</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>datasalt pangool</td>\n",
       "      <td>datasalt/pangool</td>\n",
       "      <td>13</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ampcrowd</td>\n",
       "      <td>amplab/ampcrowd</td>\n",
       "      <td>12</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ebay oink</td>\n",
       "      <td>eBay/oink</td>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>seqpig</td>\n",
       "      <td>HadoopGenomics/SeqPig</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>hparser</td>\n",
       "      <td>hotchpotch/hparser</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>streamdrill</td>\n",
       "      <td>streamdrill/streamdrill-core</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>parsely streamparse</td>\n",
       "      <td>goavki/streamparser</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>scaleout hserver</td>\n",
       "      <td>scaleoutsoftware/hServer</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       package                       full_name  forks  stars\n",
       "49                apache spark                    apache/spark  13341  14241\n",
       "25               apache hadoop                   apache/hadoop   3452   3712\n",
       "0                 apache storm                    apache/storm   3295   4471\n",
       "57                apache flink                    apache/flink   1851   2686\n",
       "14           metamarkets druid                  druid-io/druid   1311   5401\n",
       "28                      drools                 kiegroup/drools   1179   1071\n",
       "24                   hazelcast             hazelcast/hazelcast    917   2210\n",
       "39                 apache beam                     apache/beam    800   1372\n",
       "31               apache ignite                   apache/ignite    678   1165\n",
       "38            twitter scalding                twitter/scalding    637   2868\n",
       "40               twitter heron                   twitter/heron    518   2886\n",
       "30                        kryo           EsotericSoftware/kryo    503   2838\n",
       "37                  apache pig                      apache/pig    411    503\n",
       "68  getstream stream framework  tschellenbach/Stream-Framework    388   3137\n",
       "50                        snap              snap-stanford/snap    348    685\n",
       "45                        oryx                OryxProject/oryx    312   1224\n",
       "55    spring for apache hadoop   spring-projects/spring-hadoop    308    489\n",
       "11                       blaze                     blaze/blaze    289   2109\n",
       "51                 nokia disco              discoproject/disco    248   1471\n",
       "42         twitter summingbird             twitter/summingbird    247   1883\n",
       "70        concurrent cascading               cwensel/cascading    223    297\n",
       "3              twitter gizzard         twitter-archive/gizzard    209   2143\n",
       "5                    pachyderm             pachyderm/pachyderm    207   2143\n",
       "2                         kite                   kite-sdk/kite    203    299\n",
       "60                  geotrellis         locationtech/geotrellis    192    606\n",
       "7                     cascalog             nathanmarz/cascalog    179   1306\n",
       "27        gis tools for hadoop       Esri/gis-tools-for-hadoop    169    311\n",
       "47      apache spark streaming      yahoo/streaming-benchmarks    161    294\n",
       "43                apache samza                    apache/samza    160    352\n",
       "36                 apache apex                apache/apex-core    158    254\n",
       "..                         ...                             ...    ...    ...\n",
       "18                 apache gora                     apache/gora     66     61\n",
       "62             linkedin cubert                 linkedin/Cubert     60    233\n",
       "63              spark-dataflow            jhlch/spark-dataflow     60      0\n",
       "54              netflix pigpen                  Netflix/PigPen     57    469\n",
       "15                distributedr            vertica/DistributedR     57    143\n",
       "34                      pigpen                  Netflix/PigPen     57    469\n",
       "41                netflix zeno                    Netflix/zeno     55    190\n",
       "22            apache mapreduce         apache/hadoop-mapreduce     54     40\n",
       "33                     arvados               curoverse/arvados     47    141\n",
       "71                      pydoop                     crs4/pydoop     46    122\n",
       "10              succinct spark                 amplab/succinct     43    170\n",
       "1            stratio crossdata               Stratio/crossdata     40    152\n",
       "56           streamsx.topology    IBMStreams/streamsx.topology     36     16\n",
       "12              netflix staash                  Netflix/staash     36    169\n",
       "75                       tigon                  caskdata/tigon     35    243\n",
       "67                       akela           mozilla-metrics/akela     29     77\n",
       "21                apache twill                    apache/twill     26     26\n",
       "16      sigmoidanalytics spork          sigmoidanalytics/spork     26     85\n",
       "13                       skale           skale-me/skale-engine     23    159\n",
       "65            damballa parkour                damballa/parkour     19    259\n",
       "53                   apache s4             apache/incubator-s4     17     36\n",
       "59                       tuktu          UnderstandLingBV/Tuktu     15     48\n",
       "9             datasalt pangool                datasalt/pangool     13     59\n",
       "32                    ampcrowd                 amplab/ampcrowd     12     46\n",
       "19                   ebay oink                       eBay/oink      8     23\n",
       "44                      seqpig           HadoopGenomics/SeqPig      6      9\n",
       "61                     hparser              hotchpotch/hparser      5     24\n",
       "74                 streamdrill    streamdrill/streamdrill-core      3      6\n",
       "8          parsely streamparse             goavki/streamparser      1      3\n",
       "66            scaleout hserver        scaleoutsoftware/hServer      1      3\n",
       "\n",
       "[76 rows x 4 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "github.sort_values(['forks'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get StackOverflow Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "baseurl = 'https://api.stackexchange.com/2.2/search/advanced'\n",
    "\n",
    "def get_so_stats(package, tag):\n",
    "#Given tag, return tag counts, and count of questions countaining the tag name\n",
    "    params = {\n",
    "    \"site\": \"stackoverflow\",\n",
    "    \"key\": \"y38PeNERQJQIC8EPliKAVQ((\",\n",
    "    \"tagged\": tag,  \n",
    "    \"filter\": 'total'}\n",
    "    try:\n",
    "        r1 = requests.get(baseurl, params=params)\n",
    "        so_tag_counts = r1.json()['total']\n",
    "    except:\n",
    "        so_tag_counts = 0\n",
    "    params = {\n",
    "    \"site\": \"stackoverflow\",\n",
    "    \"key\": \"y38PeNERQJQIC8EPliKAVQ((\",\n",
    "    \"q\": tag,  \n",
    "    \"filter\": \"total\"}\n",
    "    try:\n",
    "        r = requests.get(baseurl, params=params)\n",
    "        return {'package':package, 'so_alias': tag,'so_tag_count': so_tag_counts, 'so_question_count': r.json()['total']}\n",
    "    except:\n",
    "        return {'package':package, 'so_alias': tag,'so_tag_count': so_tag_counts, 'so_question_count': 0}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tags = [pkg.replace(' ','-') for pkg in pkgs]\n",
    "pkg_tag = zip(pkgs,tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "so_data = []\n",
    "for (package, tag) in pkg_tag:\n",
    "    so_data.append(get_so_stats(package, tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "so_DF = pd.DataFrame(so_data)[['package','so_alias', 'so_tag_count', 'so_question_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## manually change some of the package tags to match SO tag database\n",
    "def replace_tag_stats(package, tag):\n",
    "    res = get_so_stats(package, tag)\n",
    "    so_DF.loc[so_DF['package'] == package, 'so_alias'] = tag\n",
    "    so_DF.loc[so_DF['package'] == package, 'so_tag_count'] = res['so_tag_count']\n",
    "    so_DF.loc[so_DF['package'] == package, 'so_question_count'] = res['so_question_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "so_tags = [('parsely streamparse', 'streamparse'),\n",
    "            ('metamarkets druid', 'druid'),\n",
    "            ('apache gora', 'gora'),\n",
    "            ('apache hadoop', 'hadoop'),\n",
    "            ('snap', 'stanford network analysis platform'),\n",
    "            ('nokia disco', 'disco'),\n",
    "            ('concurrent cascading', 'cascading'),\n",
    "            ('apache hama', 'hama'),\n",
    "            ('apache ignite', 'ignite'),\n",
    "            ('twitter scalding', 'scalding')]\n",
    "\n",
    "for (package, tag) in so_tags:\n",
    "    replace_tag_stats(package, tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "so_DF.to_csv(\"../data/DC_pkgs_results_stackoverflow.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Get Google Search Results Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"../code/secrets/google_token.nogit\", \"rb\") as f:\n",
    "    my_api_key = f.read()\n",
    "    \n",
    "with open(\"../code/secrets/cse_token.nogit\", \"rb\") as f:\n",
    "    my_cse_id = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def google_search_results_count(package, search_term, api_key, cse_id):\n",
    "    search_term = search_term.replace(' ','+')\n",
    "    r= requests.get('https://www.googleapis.com/customsearch/v1?q='+search_term+'+&alt=json&cx='+my_cse_id+\n",
    "                    '&rc=1&key='+my_api_key)\n",
    "    res = r.json()['searchInformation']\n",
    "    return {'package': package, 'search_term': search_term, 'search_results': res['totalResults']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = [res for res in (google_search_results_count(q, q, my_api_key, my_cse_id) for q in pkgs)\n",
    "        if res is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "googleDF = pd.DataFrame(data)[['package', 'search_term', 'search_results']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## some packages have very common names (ie, lipstick and kite) more specific search terms were used for google\n",
    "def replace_google_stats(package, alias):\n",
    "    res = google_search_results_count(package, alias, my_api_key, my_cse_id)\n",
    "    googleDF.loc[googleDF['package'] == package, 'search_term'] = res['search_term']\n",
    "    googleDF.loc[googleDF['package'] == package, 'search_results'] = res['search_results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "good_search_terms = [('kite', 'kite API'),\n",
    "                     ('skale', 'skale engine'),\n",
    "                     ('oryx', 'oryx framework'),\n",
    "                     ('akela', 'mozilla akela'),\n",
    "                     ('snap', '\"stanford network analysis platform\"'),\n",
    "                     ('netflix lipstick','lipstick apache'),\n",
    "                     ('blaze', 'blaze python'),\n",
    "                     ('pachyderm', 'pachyderm pipeline'),\n",
    "                     ('twitter heron','twitter heron stream'),\n",
    "                     ('streamsx.topology','IBMStreams streamsx.topology'),\n",
    "                     ('drools', 'kiegroup drools'),\n",
    "                     ('gearpump', 'apache gearpump'),\n",
    "                     ('onyx', 'onyx platform')]\n",
    "for (package, term) in good_search_terms:\n",
    "    replace_google_stats(package, term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "googleDF.to_csv(\"../data/DC_packages_results_google.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dcpkgsDF = github.merge(so_DF, on='package', copy = False)\n",
    "dcpkgsDF = dcpkgsDF.merge(googleDF, on='package', copy = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dcpkgsDF.to_csv(\"../output/distributed_computing_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
